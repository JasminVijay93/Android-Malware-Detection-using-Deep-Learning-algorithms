{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, MaxPooling1D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "#reading input data\n",
    "df=pd.read_csv('C://Users//jazzj//Downloads//Maldroid//final datasets//SMS_MMD.csv')\n",
    "df=df.fillna(0)\n",
    "df = df.iloc[:,1:]\n",
    "df1=df\n",
    "\n",
    "\n",
    "#dropping apk name and class name\n",
    "df1= df.drop('apk',axis=1)\n",
    "df2= df1.drop('class',axis=1)\n",
    "\n",
    "\n",
    "#transforming the class column to numerical values\n",
    "le = LabelEncoder()\n",
    "df1['class']=le.fit_transform(df1['class']) \n",
    "\n",
    "\n",
    "#ASsigning X and y\n",
    "X= df2\n",
    "y = df1['class']\n",
    "\n",
    "\n",
    "#Identifying the count of malware and benign records\n",
    "print('The count of malicious and beneign are',y.value_counts())\n",
    "\n",
    "#Splitting the training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80)\n",
    "\n",
    "\n",
    "\n",
    "print('Shape of X_train is',X_train.shape)\n",
    "print('Shape of Y_train is',y_train.shape)\n",
    "print('Shape of X_test is',X_test.shape)\n",
    "print('Shape of Y_test is',y_test.shape)\n",
    "\n",
    "\n",
    "#Transforming the dataset\n",
    "nb_class = 2\n",
    "nb_features = 20 # number of features per features type (shape, texture, margin) \n",
    "scaler = StandardScaler()        \n",
    "X_train = scaler.fit_transform(X_train)        \n",
    "X_test = scaler.fit_transform(X_test)\n",
    "print('Shape of X_train after scalar is',X_train.shape)\n",
    "print('Shape of Y_train after scalar is',y_train.shape)\n",
    "label_as_binary = LabelBinarizer()\n",
    "train__y_labels = label_as_binary.fit_transform(y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Converting the X values from 2 dim to 3 dim\n",
    "X_train_A = X_train.reshape((X_train.shape[0],X_train.shape[1], 1))\n",
    "X_test_A = X_test.reshape((X_test.shape[0],X_test.shape[1],1)) \n",
    "\n",
    "\n",
    "def model_function():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #adding the input shape\n",
    "    model.add(Input(shape=X_train_A.shape[1:]))\n",
    "\n",
    "    #adding the first input layer\n",
    "    model.add(Conv1D(16, 61, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(renorm=True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(2, strides=2, padding=\"valid\"))\n",
    "    \n",
    "    #adding the second layer\n",
    "    model.add(Conv1D(32, 3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(renorm=True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(2, strides=2, padding=\"valid\"))\n",
    "    \n",
    "    #adding the 3rd layer\n",
    "    model.add(Conv1D(64, 3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(renorm=True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(2, strides=2, padding=\"valid\"))\n",
    "    \n",
    "    #adding the 3rd layer\n",
    "    model.add(Conv1D(64, 3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(renorm=True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(2, strides=2, padding=\"valid\"))\n",
    "    \n",
    "    #adding the 4th layer\n",
    "    model.add(Conv1D(64, 3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(renorm=True))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #adding fully connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #adding the output layer\n",
    "    model.add(Dense(2),kernel_regularizer=regularizers.l2(l2_coef))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    sgd = SGD(learning_rate=0.05, nesterov=True, decay=1e-5, momentum=0.9) \n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    #fit the model\n",
    "    model.fit(X_train_A,y_train,epochs=10,shuffle=False, batch_size=300,validation_data=(X_test_A, y_test))\n",
    "\n",
    "    model.evaluate(X_train_A,y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "#Calling the training model\n",
    "cnn=model_function()\n",
    "\n",
    "#Evaluate the model\n",
    "test_loss, test_acc = cnn.evaluate(X_test_A, y_test)\n",
    "\n",
    "print(\"Accuracy of the CNN,\",round((test_acc*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6afd896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
